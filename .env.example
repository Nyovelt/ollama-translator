# Default Ollama API configuration
NEXT_PUBLIC_DEFAULT_API_URL=http://localhost:11434
NEXT_PUBLIC_DEFAULT_MODEL=llama3.1
NEXT_PUBLIC_DEFAULT_API_KEY=

# Default configuration to use (optional)
# Options: 'ollama-default', 'openai', or 'custom-default'
NEXT_PUBLIC_DEFAULT_CONFIG_ID=ollama-default

# Custom LLM configuration (optional)
# If all custom fields are provided, it will be added as the default option
NEXT_PUBLIC_CUSTOM_LLM_NAME=
NEXT_PUBLIC_CUSTOM_API_URL=
NEXT_PUBLIC_CUSTOM_MODEL=
NEXT_PUBLIC_CUSTOM_API_KEY=

# Examples of custom configurations:

# For Together AI:
# NEXT_PUBLIC_CUSTOM_LLM_NAME=Together AI
# NEXT_PUBLIC_CUSTOM_API_URL=https://api.together.xyz/v1
# NEXT_PUBLIC_CUSTOM_MODEL=meta-llama/Llama-2-7b-chat-hf
# NEXT_PUBLIC_CUSTOM_API_KEY=your_together_api_key

# For Groq:
# NEXT_PUBLIC_CUSTOM_LLM_NAME=Groq
# NEXT_PUBLIC_CUSTOM_API_URL=https://api.groq.com/openai/v1
# NEXT_PUBLIC_CUSTOM_MODEL=llama3-8b-8192
# NEXT_PUBLIC_CUSTOM_API_KEY=your_groq_api_key

# For local LM Studio:
# NEXT_PUBLIC_CUSTOM_LLM_NAME=LM Studio
# NEXT_PUBLIC_CUSTOM_API_URL=http://localhost:1234/v1
# NEXT_PUBLIC_CUSTOM_MODEL=local-model
